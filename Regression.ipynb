{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия\n",
    "\n",
    "## Постановка задачи\n",
    "\n",
    "Представим, что мы хотим определить цену в одном доме квартиры на основании площади квартиры. У нас есть база данных полученная от риэлтерской компании. В данном случае нам нужно найти зависимость между площадью квартиры и ценой квартиры. То есть, нужно найти функцию $f(X) = y$, где $X$ это площадь квартиры, а $y$ это цена на квартиру. Это и есть задача регрессии.\n",
    "\n",
    "Давайте загрузим и визуализируем данные. Для этого нажмите *Ctrl+Enter* на следующей ячейке. После этого в вектре $X$ у нас будет площадь квартиры в $м^2$, а в вектре $y$ цена на квартиру. А внизу ячейки у нас будет диаграмму с точками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression_helper import * # не обращайте внимание на эту строчку\n",
    "X, y = get_data()    # Загружаем данные в X и y\n",
    "plot_data(X, y)      # Строим диаграму с точками \n",
    "print_table_with_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы предполагаем, что данная зависимость может описаться линейной функцией вида $y = kX$. Это наша гипотеза. Давайте нанесем на график несколько линейных функциях с разным коэффициентом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_slope(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть гипотезы. Но как численно определить какая из них лучшая?\n",
    "\n",
    "Для это введем функцию ошибку. Функция ошибки - численное значение того, как наша гипотеза хорошо моделирует функцию.\n",
    "\n",
    "Пусть у нас есть функция (наша модель)  $f(X) = kX = \\hat{y}$. То есть, $\\hat{y}$ является предсказанными нами значениями для X. А настоящие значения будут равны $y$.\n",
    "\n",
    "Тогда определим нашу функцию ошибки от параметра k:\n",
    "\n",
    "$J(k) = \\frac{1}{2N}\\sum_{i=0}^{N}{(\\hat{y_i} - y_i)^2}= \\frac{1}{2N} \\sum_{i=0}^{N}{(f(X_i) - y_i)^2} = \\frac{1}{2N} \\sum_{i=0}^{N}{(kX_i - y_i)^2} $\n",
    "\n",
    "Где $N$ - это количество квартир, $X_i$ - это площадь i-oй квартиры, $y_i$ - цена для i-oй квартиры, $\\hat{y_i}$ - предсказанная цена для i-oй квартиры.\n",
    "      \n",
    "Например, $X_2=36$, $y_3=5500000.0$\n",
    "\n",
    "$\\sum_{i=0}^{N}$  - это знак суммирования.\n",
    "Например, у нас есть $a_0, a_2, a_3, \\cdots a_N$. Тогда $\\sum_{i=0}^{N}{a_i} = a_0 + a_2 + a_3 + \\cdots + a_N$\n",
    "\n",
    "Ниже у нас есть пример с визуализацией ошибки для одной из гипотез.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_and_error(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте визуализируем ошибки для наших гипотез."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_and_J(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Давайте теперь визуализируем всю функцию ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_J(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Наша задачи - это минимизации функции ошибки. \n",
    "Я думаю, что вы знаете как можно найти значение минимума для данной функции. Нужно взять производную функции ошибки и приравнять ее к нулю. $J'(k) = \\frac{dJ(k)}{dk} = 0$.\n",
    "\n",
    "В данном случае производную можно рассматривать $f'(x_0) = \\frac{f(x_0+\\epsilon) - f(x_0)}{\\epsilon}, \\epsilon \\rightarrow 0$ \n",
    "\n",
    "![alt](img\\der.jpg) \n",
    "\n",
    "Например, для функции $f(x) = x^2$, $f'(x) = \\frac{(x+\\epsilon)^2 - x^2}{\\epsilon} = \\frac{x^2+ 2x\\epsilon + \\epsilon^2 - x^2}{\\epsilon}= \\frac{2x\\epsilon + \\epsilon^2}{\\epsilon} = 2x + \\epsilon = 2x$\n",
    "\n",
    "$\\epsilon \\rightarrow 0$\n",
    "\n",
    "Таким образом, в нашем случае:\n",
    "\n",
    "$J'(k) = \\frac{dJ(k)}{dk} = \\frac{d}{dk}(\\frac{1}{2N}\\sum_{i=1}^{N}{(y_i - \\hat{y_i})^2}) \n",
    "= 2 \\cdot \\frac{1}{2N}\\sum_{i=1}^{N} (kX_i - y_i)\\frac{d}{dk}(kX_i - y_i) =\n",
    "          \\frac{1}{N} \\sum_{i=1}^{N} (kX_i - y_i)X_i = 0$ \n",
    "\n",
    "Решив уравнение, мы получим значение для $k=185072.4$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_and_hyp(X, y, 185072.4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Но в реальных приложениях не всегда возможно решить это уравнение (далее я расскажу поподробнее о таких ситуациях). Поэтому, познакомимся с такой техникой как градиентный спуск. Как вызнаете, значение производной в точке равно значению тангенса угла наклона касательной в данной точке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_J_with_der(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую эту информацию мы можем понять где находится минимум и изменить значение $k$ в сторону минимума. Если производная положительная (как касательная в точке 190000), то нам нужно уменьшать значение $k$. Если производная отрицательная (как касательная в точке 180000), то нам нужно увеличить значение $k$.  \n",
    "\n",
    "Таким образом сам алгоритм градиентного спуска можно описать следующим образом.\n",
    "\n",
    "* Выбираем случайное значение для $k$\n",
    "* Повторить пока не сойдется:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k = k - \\alpha \\cdot \\frac{d}{dk} J(k)$\n",
    "\n",
    "Где $\\alpha$ это коэффициент, который мы выбреем. Теперь поэкспериментируем со значением $\\alpha$ и начальным значением коэффициента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traice(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цена квартиры в зависимости от площади и дальности квплощадьартиры от центра Москвы\n",
    "Допустим теперь нам требуется определить цену квартиры в зависимости от квартиры и дальности квартиры от центра Москвы. То есть, теперь у нас есть 2 параметра. И наша функция, которую мы хотим найти будет выглядеть вот так $y = F(X^{площадь}, X^{дальность})$, где $X^{площадь}$ площадь квартиры в $м^2$, $X^{дальность}$ дальность квартиры от центра в км, а $y$ цена на квартиру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_square, X_distance, y = get_new_data()\n",
    "print_3d_table_with_data(X_square, X_distance, y)\n",
    "plot_new_3d_data(X_square, X_distance, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения данной проблемы введем нашу гипотезу: $f(X) = k_0 + k_1 X^{площадь} + k_2 X^{дальность} = \\hat{y}$. Это линейная функция для двух входных параметров.\n",
    "\n",
    "Тогда определим нашу функцию ошибки от параметров $k_0, k_1, k_2$:\n",
    "\n",
    "$J(k) = \\frac{1}{2N}\\sum_{i=1}^{N}{(\\hat{y_i} - y_i)^2}= \\frac{1}{2N} \\sum_{i=1}^{N}{k_0 + k_1 X^{площадь} + k_2 X^{дальность}  - y_i)^2}$\n",
    "\n",
    "Где $N$ - это количество квартир, $X^{площадь}_i$ - это площадь i-oй квартиры, $X^{дальность}_i$ - это расстояние квартиры до центра Москвы, а $y_i$ - цена для i-oй квартиры, $\\hat{y_i}$ - предсказанная цена для i-oй квартиры.\n",
    "\n",
    "Для нахождения этих коэффициентов также используем градиентный спуск. Но теперь нам необходимо найти производную от функции ошибки для каждого коэффициента.\n",
    "\n",
    "$\\frac{\\delta  J(k_0, k_1, k_2)}{\\delta k_0} = \\frac{1}{N}\\sum_{i=1}^{N} (k_0 + k_1 X^{площадь}_i + k_2 X^{дальность}_i  - y_i)$ \n",
    "\n",
    "$\\frac{\\delta J(k_0, k_1, k_2)}{\\delta k_1} = \\frac{1}{N}\\sum_{i=1}^{N} (k_0 + k_1 X^{площадь}_i + k_2 X^{дальность}_i  - y_i)X^{площадь}_i$ \n",
    "\n",
    "$\\frac{\\delta J(k_0, k_1, k_2)}{\\delta k_2} = \\frac{1}{N}\\sum_{i=1}^{N} (k_0 + k_1 X^{площадь}_i + k_2 X^{дальность}_i - y_i)X^{дальность}_i$ \n",
    "\n",
    "Мы также можем приравнять каждую производную к нулю и найти решение системы уравнений. Но делать это не целесообразно. Для решения данной системы в компьютере потребуется построить матричное уравнение. А в процессе решения потребуется найти обратную матрицу. Данная операция является очень медленной, даже на современных компьютерах. В данном примере у нас всего 2 входных параметра и 20 значений $X$. Вычисления обратной матрицы для нашего примера займет микросекунды. Но в реальных приложениях обычно бывает и по десяткам тысяч входных параметров и сотни миллионов значений. Нахождения обратной матриц для таких задач займет несравнимо много времени по сравнению с градиентным спуском. Поэтому в промышленности применяется именно градиентный спуск. \n",
    "\n",
    "Полный алгоритм градиентного спуска c $M$ коэффициентами можно описать следующим образом.\n",
    "\n",
    "* Выбираем случайное значение для $k_0, k_1, ... k_M$\n",
    "* Повторить пока не сойдется:\n",
    "\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_0 = k_0 - \\alpha \\cdot \\frac{\\delta }{\\delta k_0} J(k_0, k_1, ... k_M)$ \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_1 = k_1 - \\alpha \\cdot \\frac{\\delta }{\\delta k_1} J(k_0, k_1, ... k_M)$\n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ \\cdots $ \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_M = k_M - \\alpha \\cdot \\frac{\\delta }{\\delta k_M} J(k_0, k_1, ... k_M)$ \n",
    "    \n",
    "\n",
    "Где $\\alpha$ это коэффициент, который мы выбираем. \n",
    "\n",
    "Давайте теперь визуализируем ошибку.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_in_3d(X_square, X_distance, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда если мы используем формулы выше, то мы увидим следующую картину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0.0001\n",
    "k1, k2 = lin_grad_full(X_square, X_distance, y, alpha=a, iters=50, k0_init=5000000, k1_init=500000, k2_init=-200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь визуализируеим полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new_data_and_hyp(X_square, X_distance, y, 5000000, k1, k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переобучение и слишком простая модель\n",
    "\n",
    "Как вы понимаете линейные функции не всегда могут быть использована для все данных. Например, допустим у нас есть следующий набор данных:\n",
    "\n",
    "![alt](img\\new_data.png)\n",
    "\n",
    "Линейная регрессия может предсказать только прямую линию, но тут такое не пойдет. Нам нужно что-то по сложнее. То есть, наша модель слишком простая.\n",
    "\n",
    "## Полиномы\n",
    "\n",
    "Полиномом степени n называется функция $f(X) = k_n X^n + k_{n-1} X^{n-1}  \\ldots + k_1 X + k_0$. Известное вам квадратное уравнение — это полином второй степени. $f(X) = k_2 X^2 + k_1 X + k_0$\n",
    "\n",
    "![alt](img\\polynomes.png)\n",
    "\n",
    "В дальнейшем мы будем использовать полиномиальную регрессию. Но я не буду обсуждать то, как она работает. \n",
    "\n",
    "Давайте получим и визуализируем новые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_poly_data()\n",
    "plot_more_poly_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как различные полиномы могут репрезентировать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poly_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но нужно помнить, что не всегда у нас может быть хороший набор данных. Допустим после того как мы обучили нашу модель мы собрали еще данных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = get_more_poly_data()\n",
    "plot_more_poly_data(X, y, X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на ошибку также на новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poly_data(X, y, X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, слишком сложная модель переобучается на данных. \n",
    "\n",
    "Для решения этой проблемы мы делим наши данные на обучающий набор и тестовый набор. Модель обучается на тестовом наборе, но окончательная оценка производится по тестовому набору. \n",
    "\n",
    "## Пример переобучения человека\n",
    "\n",
    "\n",
    "![alt](img\\illusion.jpg)\n",
    "\n",
    "![alt](img\\illusion2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "1. Сделать линейную функцию\n",
    "2. Сделать функцию ошибки\n",
    "3. Рассчитать градиент\n",
    "4. Реализовать градиентный спуск\n",
    "\n",
    "Задания следует делать одно за другим.\n",
    "\n",
    "Для начала запустим следующую ячейку, которая визуализирует наши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # подгружаем дополнительную библиотеку\n",
    "from regression_task import *\n",
    "\n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализовать линейную функцию вида $y = kx$. \n",
    "   На вход функции передается значение коэффициента $\\mathbf{k}$ (действительное число), и вектор-столбец $\\mathbf{X}$ размера Nx1. Функция должна  возвращать вектор-столбец $\\mathbf{y}$ размера Nx1. \n",
    "   То есть, вектор столбец y можно записать как:\n",
    "   \n",
    "   \\begin{equation*}\n",
    "    \\mathbf{y} = \\begin{pmatrix}\n",
    "    y_0 \\\\\n",
    "    y_1 \\\\\n",
    "    \\cdots \\\\\n",
    "    y_N \\\\\n",
    "    \\end{pmatrix} = \n",
    "    \\begin{pmatrix}\n",
    "    k x_1 \\\\\n",
    "    k x_2 \\\\\n",
    "    \\cdots \\\\\n",
    "    k x_N \\\\\n",
    "    \\end{pmatrix}\n",
    "    \\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(k, X):\n",
    "    # Напоминаю, что код нужно писать в области между звездочками. \n",
    "    # Вы можете решить данную задачу с помощью цикла, но \n",
    "    # постарайтесь решить ее с помощью векторизации.\n",
    "\n",
    "    y = np.zeros_like(X) # создаем переменную y и заполняем ее нулями\n",
    "    N = X.shape[0]       # получаем размер вектора столбца\n",
    "\n",
    "    #***********************************************************************\n",
    "    \n",
    "   \n",
    "    \n",
    "    #***********************************************************************\n",
    "\n",
    "    return y\n",
    " \n",
    "check_linear_function(linear_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализовать функцию потерь $J(k) = \\frac{1}{2N}\\sum_{i=0}^{N}{(\\hat{y_i} - y_i)^2}= \\frac{1}{2N} \\sum_{i=0}^{N}{(f(X_i) - y_i)^2}$\n",
    "\n",
    "На вход функции передается значение коэффициента $\\mathbf{k}$ (действительное число), и вектор-столбец $\\mathbf{X}$ размера Nx1 и вектор-столбец $\\mathbf{y}$ c с реальными значениями размера Nx1. Функция должна возвращать действительное число равное $J(k)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(k, X, y):\n",
    "    # Ты можешь использовать функцию linear_function из предыдущего задания\n",
    "    # Для того, что бы найти значение f(X)\n",
    "    # Не бойся создавать новые переменные. \n",
    "    # Помни что ты можешь вычитать один из другого, а также помни что,\n",
    "    # ты можешь почленно вводить в степень вектор. \n",
    "    \n",
    "    # Результат функции потерь должен быть записан в переменную J\n",
    "   \n",
    "    \n",
    "    N = X.shape[0]       # получаем размер вектора столбца\n",
    "    \n",
    "    J = 0\n",
    "\n",
    "    #***********************************************************************\n",
    "    \n",
    "\n",
    "    #***********************************************************************\n",
    "\n",
    "    return J\n",
    "   \n",
    "check_loss_function(loss_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализовать градиент(произвоодную) $J'(k) = \\frac{dJ(k)}{dk} = \\frac{1}{N} \\sum_{i=1}^{N} (f(X_i) - y_i) X_i  = \\frac{1}{N} \\sum_{i=1}^{N} (kX_i - y_i) X_i$ \n",
    "          \n",
    "          \n",
    "На вход функции передается значение коэффициента $\\mathbf{k}$ (действительное число), и вектор-столбец $\\mathbf{X}$ размера Nx1 и вектор-столбец $\\mathbf{y}$ c с реальными значениями размера Nx1. Функция должна возвращать градиент равный $J'(k)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(k, X, y):\n",
    "    # Ты можешь использовать функцию linear_function из предыдущего задания\n",
    "    # Для того, что бы найти значение f(X)\n",
    "    # Не бойся создавать новые переменные. \n",
    "    # Помни что ты можешь вычитать один из другого, а также помни что,\n",
    "    # ты можешь почленно перемножать вектора вектор. \n",
    "    \n",
    "    # Результат функции потерь должен быть записан в переменную grad\n",
    "        \n",
    "    N = X.shape[0]       # получаем размер вектора столбца\n",
    "    \n",
    "    grad = 0\n",
    "\n",
    "    #***********************************************************************\n",
    "\n",
    "    #***********************************************************************\n",
    "\n",
    "    return grad\n",
    "   \n",
    "check_gradient_function(gradient_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Финишная прямая. Пора реализовать алгоритм градиентного спуска. \n",
    "На вход функции передается начальное значение коэффициента $\\mathbf{k}$ (действительное число), и вектор-столбец $\\mathbf{X}$ размера Nx1 и вектор-столбец $\\mathbf{y}$ c реальными значениями размера Nx1, значение коэффициента альфа $\\alpha$ и число $iters$ равное количеству итераций в алгоритме. \n",
    "Сам алгоритм мы будем использовать в следующем виде\n",
    "* Повторить $iters$ раз:\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k = k - \\alpha \\cdot J'(k)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(k_init, X, y, alpha, iters):\n",
    "    # Лучше всего использовать функцию gradient_function для \n",
    "    # нахождения градиента, чем пересчитывать его еще раз\n",
    "    \n",
    "    # И еше я прошу перед тем как изменить значение k в массиве \n",
    "    # k_old.\n",
    "    # Например, i это счетчик цикла.\n",
    "    # Тогда значение k можно сохранить как k_old[i] = k\n",
    "        \n",
    "    k = k_init\n",
    "    k_old = np.array([0.0]*iters)\n",
    "\n",
    "\n",
    "    #***********************************************************************\n",
    "\n",
    "\n",
    "    #***********************************************************************\n",
    "\n",
    "    return k, k_old\n",
    "    \n",
    "check_gradient_descent(gradient_descent)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
