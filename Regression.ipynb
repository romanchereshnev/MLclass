{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия\n",
    "\n",
    "## Постановка задачи\n",
    "\n",
    "Представим, что мы хотим определить цену в одном доме квартиры на основании площади квартиры. У нас есть база данных полученная от риэлтерской компании. В данном случае нам нужно найти зависимость между площадью квартиры и ценой квартиры. То есть, нужно найти функцию $f(X) = y$, где $X$ это площадь квартиры, а $y$ это цена на квартиру. Это и есть задача регрессии.\n",
    "\n",
    "Давайте загрузим и визуализируем данные. Для этого нажмите *Ctrl+Enter* на следующей ячейке. После этого в вектре $X$ у нас будет площадь квартиры в $м^2$, а в вектре $y$ цена на квартиру. А внизу ячейки у нас будет диаграмму с точками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression_helper import * # не обращайте внимание на эту строчку\n",
    "X, y = get_data()    # Загружаем данные в X и y\n",
    "plot_data(X, y)      # Строим диаграму с точками \n",
    "print_table_with_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы предполагаем, что данная зависимость может описаться линейной функцией вида $y = kX$. Это наша гипотеза. Давайте нанесем на график несколько линейных функциях с разным коэффициентом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_slope(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть гипотезы. Но как численно определить какая из них лучшая?\n",
    "\n",
    "Для это введем функцию ошибку. Функция ошибки - численное значение того, как наша гипотеза хорошо моделирует функцию.\n",
    "\n",
    "Пусть у нас есть функция (наша модель)  $f(X) = kX = \\hat{y}$. То есть, $\\hat{y}$ является предсказанными нами значениями для X. А настоящие значения будут равны $y$.\n",
    "\n",
    "Тогда определим нашу функцию ошибки от параметра k:\n",
    "\n",
    "$J(k) = \\frac{1}{2N}\\sum_{i=0}^{N}{(\\hat{y_i} - y_i)^2}= \\frac{1}{2N} \\sum_{i=0}^{N}{(f(X_i) - y_i)^2} = \\frac{1}{2N} \\sum_{i=0}^{N}{(kX_i - y_i)^2} $\n",
    "\n",
    "Где $N$ - это количество квартир, $X_i$ - это площадь i-oй квартиры, $y_i$ - цена для i-oй квартиры, $\\hat{y_i}$ - предсказанная цена для i-oй квартиры.\n",
    "      \n",
    "Например, $X_2=36$, $y_3=5500000.0$\n",
    "\n",
    "$\\sum_{i=0}^{N}$  - это знак суммирования.\n",
    "Например, у нас есть $a_0, a_2, a_3, \\cdots a_N$. Тогда $\\sum_{i=0}^{N}{a_i} = a_0 + a_2 + a_3 + \\cdots + a_N$\n",
    "\n",
    "Ниже у нас есть пример с визуализацией ошибки для одной из гипотез.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_and_error(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте визуализируем ошибки для наших гипотез."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_and_J(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Давайте теперь визуализируем всю функцию ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_J(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Наша задачи - это минимизации функции ошибки. \n",
    "Я думаю, что вы знаете как можно найти значение минимума для данной функции. Нужно взять производную функции ошибки и приравнять ее к нулю. $J'(k) = \\frac{dJ(k)}{dk} = 0$.\n",
    "\n",
    "В данном случае производную можно рассматривать $f'(x_0) = \\frac{f(x_0+\\epsilon) - f(x_0)}{\\epsilon}, \\epsilon \\rightarrow 0$ \n",
    "\n",
    "![alt](img\\der.jpg) \n",
    "\n",
    "Например, для функции $f(x) = x^2$, $f'(x) = \\frac{(x+\\epsilon)^2 - x^2}{\\epsilon} = \\frac{x^2+ 2x\\epsilon + \\epsilon^2 - x^2}{\\epsilon}= \\frac{2x\\epsilon + \\epsilon^2}{\\epsilon} = 2x + \\epsilon = 2x$\n",
    "\n",
    "$\\epsilon \\rightarrow 0$\n",
    "\n",
    "Таким образом, в нашем случае:\n",
    "\n",
    "$J'(k) = \\frac{dJ(k)}{dk} = \\frac{d}{dk}(\\frac{1}{2N}\\sum_{i=1}^{N}{(y_i - \\hat{y_i})^2}) \n",
    "= 2 \\cdot \\frac{1}{2N}\\sum_{i=1}^{N} (kX_i - y_i)\\frac{d}{dk}(kX_i - y_i) =\n",
    "          \\frac{1}{N} \\sum_{i=1}^{N} (kX_i - y_i)X_i = 0$ \n",
    "\n",
    "Решив уравнение, мы получим значение для $k=185072.4$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_and_hyp(X, y, 185072.4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Но в реальных приложениях не всегда возможно решить это уравнение (далее я расскажу поподробнее о таких ситуациях). Поэтому, познакомимся с такой техникой как градиентный спуск. Как вызнаете, значение производной в точке равно значению тангенса угла наклона касательной в данной точке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_J_with_der(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую эту информацию мы можем понять где находится минимум и изменить значение $k$ в сторону минимума. Если производная положительная (как касательная в точке 190000), то нам нужно уменьшать значение $k$. Если производная отрицательная (как касательная в точке 180000), то нам нужно увеличить значение $k$.  \n",
    "\n",
    "Таким образом сам алгоритм градиентного спуска можно описать следующим образом.\n",
    "\n",
    "* Выбираем случайное значение для $k$\n",
    "* Повторить пока не сойдется:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k = k - \\alpha \\cdot \\frac{d}{dk} J(k)$\n",
    "\n",
    "Где $\\alpha$ это коэффициент, который мы выбреем. Теперь поэкспериментируем со значением $\\alpha$ и начальным значением коэффициента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traice(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цена квартиры в зависимости от площади и дальности квартиры от центра Москвы\n",
    "Допустим теперь нам требуется определить цену квартиры в зависимости от квартиры и дальности квартиры от центра Москвы. То есть, теперь у нас есть 2 параметра. И наша функция, которую мы хотим найти будет выглядеть вот так $y = F(X_1, X_2)$, где $X_1$ площадь квартиры в $м^2$, $X_2$ дальность квартиры от центра в км, а $y$ цена на квартиру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X1, X2, y = get_new_data()\n",
    "print_3d_table_with_data(X1, X2, y)\n",
    "plot_new_3d_data(X1, X2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения данной проблемы введем нашу гипотезу: $f(X) = k_0 + k_1 X^{(1)} + k_2 X^{(2)} = \\hat{y}$. Это линейная функция для двух входных параметров.\n",
    "\n",
    "Тогда определим нашу функцию ошибки от параметров $k_0, k_1, k_2$:\n",
    "\n",
    "$J(k) = \\frac{1}{2N}\\sum_{i=1}^{N}{(\\hat{y_i} - y_i)^2}= \\frac{1}{2N} \\sum_{i=1}^{N}{k_0 + k_1 X^{(1)} + k_2 X^{(2)}  - y_i)^2}$\n",
    "\n",
    "Где $N$ - это количество квартир, $X^{(1)}_i$ - это площадь i-oй квартиры, $X^{(2)}_i$ - это расстояние квартиры до центра Москвы, а $y_i$ - цена для i-oй квартиры, $\\hat{y_i}$ - предсказанная цена для i-oй квартиры.\n",
    "\n",
    "Для нахождения этих коэффициентов также используем градиентный спуск. Но теперь нам необходимо найти производную от функции ошибки для каждого коэффициента.\n",
    "\n",
    "$\\frac{\\delta  J(k_0, k_1, k_2)}{\\delta k_0} = \\frac{1}{N}\\sum_{i=1}^{N} (k_0 + k_1 X^{(1)} + k_2 X^{(2)}  - y_i)$ \n",
    "\n",
    "$\\frac{\\delta J(k_0, k_1, k_2)}{\\delta k_1} = \\frac{1}{N}\\sum_{i=1}^{N} (k_0 + k_1 X^{(1)} + k_2 X^{(2)}  - y_i)X^{(1)}_i$ \n",
    "\n",
    "$\\frac{\\delta J(k_0, k_1, k_2)}{\\delta k_2} = \\frac{1}{N}\\sum_{i=1}^{N} (k_0 + k_1 X^{(1)} + k_2 X^{(2)} - y_i)X^{(2)}_i$ \n",
    "\n",
    "Мы также можем приравнять каждую производную к нулю и найти решение системы уравнений. Но делать это не целесообразно. Для решения данной системы в компьютере потребуется построить матричное уравнение. А в процессе решения потребуется найти обратную матрицу. Данная операция является очень медленной, даже на современных компьютерах. В данном примере у нас всего 2 входных параметра и 20 значений $X$. Вычисления обратной матрицы для нашего примера займет микросекунды. Но в реальных приложениях обычно бывает и по десяткам тысяч входных параметров и сотни миллионов значений. Нахождения обратной матриц для таких задач займет несравнимо много времени по сравнению с градиентным спуском. Поэтому в промышленности применяется именно градиентный спуск. \n",
    "\n",
    "Полный алгоритм градиентного спуска c $M$ коэффициентами можно описать следующим образом.\n",
    "\n",
    "* Выбираем случайное значение для $k_0, k_1, ... k_M$\n",
    "* Повторить пока не сойдется:\n",
    "\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_0 = k_0 - \\alpha \\cdot \\frac{\\delta }{\\delta k_0} J(k_0, k_1, ... k_M)$ \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_1 = k_1 - \\alpha \\cdot \\frac{\\delta }{\\delta k_1} J(k_0, k_1, ... k_M)$\n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ \\cdots $ \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_M = k_M - \\alpha \\cdot \\frac{\\delta }{\\delta k_M} J(k_0, k_1, ... k_M)$ \n",
    "    \n",
    "\n",
    "Где $\\alpha$ это коэффициент, который мы выбираем. \n",
    "\n",
    "Давайте теперь визуализируем ошибку.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_in_3d(X1, X2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда если мы используем формулы выше, то мы увидим следующую картину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0.0001\n",
    "k1, k2 = lin_grad_full(X1, X2, y, alpha=a, iters=50, k0_init=5000000, k1_init=500000, k2_init=-200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь визуализируеим полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new_data_and_hyp(X1, X2, y, 5000000, k1, k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переобучение и слишком простая модель\n",
    "\n",
    "Как вы понимаете линейные функции не всегда могут быть использована для все данных. Например, допустим у нас есть следующий набор данных:\n",
    "\n",
    "![alt](img\\new_data.png)\n",
    "\n",
    "Линейная регрессия может предсказать только прямую линию, но тут такое не пойдет. Нам нужно что-то по сложнее. То есть, наша модель слишком простая.\n",
    "\n",
    "## Полиномы\n",
    "\n",
    "Полиномом степени n называется функция $f(X) = k_n X^n + k_{n-1} X^{n-1}  \\ldots + k_1 X + k_0$. Известное вам квадратное уравнение — это полином второй степени. $f(X) = k_2 X^2 + k_1 X + k_0$\n",
    "\n",
    "![alt](img\\polynomes.png)\n",
    "\n",
    "В дальнейшем мы будем использовать полиномиальную регрессию. Но я не буду обсуждать то, как она работает. \n",
    "\n",
    "Давайте получим и визуализируем новые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_poly_data()\n",
    "plot_more_poly_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как различные полиномы могут репрезентировать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poly_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но нужно помнить, что не всегда у нас может быть хороший набор данных. Допустим после того как мы обучили нашу модель мы собрали еще данных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = get_more_poly_data()\n",
    "plot_more_poly_data(X, y, X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на ошибку также на новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poly_data(X, y, X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, слишком сложная модель переобучается на данных. \n",
    "\n",
    "Для решения этой проблемы мы делим наши данные на обучающий набор и тестовый набор. Модель обучается на тестовом наборе, но окончательная оценка производится по тестовому набору. \n",
    "\n",
    "## Пример переобучения человека\n",
    "\n",
    "\n",
    "![alt](img\\illusion.jpg)\n",
    "\n",
    "![alt](img\\illusion2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "* Сдалать линейную функцию\n",
    "* Сдалать функцию ошибки\n",
    "* Сдалать расчитать градиет\n",
    "* Сдалать реализовать градиентный спуск"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
